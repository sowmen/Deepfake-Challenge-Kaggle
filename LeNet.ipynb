{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LeNet.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP72oFCuUIXGxaUbH8McKxR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02bfa9367a354cfbb02dc2238faa7dbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0e92aec9911f41f39798ca5e1f7c6a2d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6afb44d74c09454091f7cafe8da0d51d",
              "IPY_MODEL_46f5dfaa9b714e739126403a1334d6c0"
            ]
          }
        },
        "0e92aec9911f41f39798ca5e1f7c6a2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6afb44d74c09454091f7cafe8da0d51d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_03456b0e1d784db6b8379186713bb664",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 200,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 200,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_18846247d24d44b6bf9c43b652d8e14d"
          }
        },
        "46f5dfaa9b714e739126403a1334d6c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_80e9ec631ed147a19ec46ca95edefaf6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 200/200 [10:21&lt;00:00,  3.11s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f88b8bd442d34288a0bcb26d0e36bb34"
          }
        },
        "03456b0e1d784db6b8379186713bb664": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "18846247d24d44b6bf9c43b652d8e14d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "80e9ec631ed147a19ec46ca95edefaf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f88b8bd442d34288a0bcb26d0e36bb34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d8499e353aea4f6db9c6e333a8ad1575": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d4315aabec3d4114abfc416bb9d286f9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e6056a8cfd9e41bba66e9987dec1856e",
              "IPY_MODEL_7015728a68ea4816b0fd84e68a1c1cdf"
            ]
          }
        },
        "d4315aabec3d4114abfc416bb9d286f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e6056a8cfd9e41bba66e9987dec1856e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e624d9b0125e4eb68053ca81354c837c",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 200,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 200,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cd22c6c16c1a4190a4bb0c85fe32e0cb"
          }
        },
        "7015728a68ea4816b0fd84e68a1c1cdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2d70e0c978ca4cc09a1395441518f3f9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 200/200 [20:14&lt;00:00,  6.07s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_071d9d43f9984c2683bc508d74e331da"
          }
        },
        "e624d9b0125e4eb68053ca81354c837c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cd22c6c16c1a4190a4bb0c85fe32e0cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2d70e0c978ca4cc09a1395441518f3f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "071d9d43f9984c2683bc508d74e331da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sowmen/Deepfake-Challenge-Kaggle/blob/master/LeNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gasqBo10-KaC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "bd9b4627-90da-4500-e97c-490689d21196"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPWWQ2Jv-XXQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import gc\n",
        "import os, sys, time\n",
        "import math\n",
        "import random\n",
        "import cv2\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "import pickle \n",
        "\n",
        "%matplotlib inline\n",
        "pd.set_option('max_colwidth', None)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6L7GoOXAXITY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "030da36f-e3ce-49e0-b7a0-059dd561e9eb"
      },
      "source": [
        "sample_df = pd.read_csv('/content/drive/My Drive/100_2.csv')\n",
        "\n",
        "real_dir = [f for f in sample_df.video_path if sample_df.loc[sample_df.video_path == f].label.item() == 0]\n",
        "fake_dir = [f for f in sample_df.video_path if sample_df.loc[sample_df.video_path == f].label.item() == 1]\n",
        "print(real_dir[0:5])\n",
        "print(fake_dir[0:5])\n",
        "\n",
        "video_dir = []\n",
        "for f in real_dir:\n",
        "    video_dir.append((f,0))\n",
        "for f in fake_dir:\n",
        "    video_dir.append((f,1))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/drive/My Drive/Dataset/dfdc_train_part_0/nweufafotd.mp4', '/content/drive/My Drive/Dataset/dfdc_train_part_0/kqlvggiqee.mp4', '/content/drive/My Drive/Dataset/dfdc_train_part_2/rbhecseopz.mp4', '/content/drive/My Drive/Dataset/dfdc_train_part_2/yrxljghbmn.mp4', '/content/drive/My Drive/Dataset/dfdc_train_part_2/iweugtdrpv.mp4']\n",
            "['/content/drive/My Drive/Dataset/dfdc_train_part_0/vstmxsekmm.mp4', '/content/drive/My Drive/Dataset/dfdc_train_part_0/pzdfwdnmyx.mp4', '/content/drive/My Drive/Dataset/dfdc_train_part_1/beoobdybbw.mp4', '/content/drive/My Drive/Dataset/dfdc_train_part_2/rxhklivqeh.mp4', '/content/drive/My Drive/Dataset/dfdc_train_part_2/zsfpyhgxmg.mp4']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3G-eanjYPPk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random.shuffle(video_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGia6c9xXoXS",
        "colab_type": "text"
      },
      "source": [
        "# **Frame Seperation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTU3-ReeXZ28",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_size = 224\n",
        "frames_per_video = 20\n",
        "\n",
        "def _read_frames_at_indices(path, capture, frame_idxs):\n",
        "    try:\n",
        "        frames = []\n",
        "        idxs_read = []\n",
        "        for frame_idx in range(frame_idxs[0], frame_idxs[-1] + 1):\n",
        "            # Get the next frame, but don't decode if we're not using it.\n",
        "            ret = capture.grab()\n",
        "            if not ret:\n",
        "                print(\"Error grabbing frame %d from movie %s\" % (frame_idx, path.split('/',4)[-1]))\n",
        "                break\n",
        "\n",
        "            # Need to look at this frame?\n",
        "            current = len(idxs_read)\n",
        "            if frame_idx == frame_idxs[current]:\n",
        "                ret, frame = capture.retrieve()\n",
        "                if not ret or frame is None:\n",
        "                    print(\"Error retrieving frame %d from movie %s\" % (frame_idx, path.split('/',4)[-1]))\n",
        "                    break\n",
        "\n",
        "                frame = _postprocess_frame(frame)\n",
        "                frames.append(frame)\n",
        "                idxs_read.append(frame_idx)\n",
        "\n",
        "        if len(frames) > 0:\n",
        "            return frames\n",
        "        print(\"No frames read from movie %s\" % path)\n",
        "        return None\n",
        "    except:\n",
        "        print(\"Exception while reading movie %s\" % path.split('/',4)[-1])\n",
        "        return None \n",
        "\n",
        "def _postprocess_frame(frame, insets=(0,0)):\n",
        "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    if insets[0] > 0:\n",
        "        W = frame.shape[1]\n",
        "        p = int(W * insets[0])\n",
        "        frame = frame[:, p:-p, :]\n",
        "\n",
        "    if insets[1] > 0:\n",
        "        H = frame.shape[1]\n",
        "        q = int(H * insets[1])\n",
        "        frame = frame[q:-q, :, :]\n",
        "\n",
        "    return frame \n",
        "\n",
        "def read_frames(path, num_frames=frames_per_video, jitter=0, seed=None):\n",
        "    \"\"\"Reads frames that are always evenly spaced throughout the video.\n",
        "\n",
        "        Arguments:\n",
        "            path: the video file\n",
        "            num_frames: how many frames to read, -1 means the entire video\n",
        "                (warning: this will take up a lot of memory!)\n",
        "            jitter: if not 0, adds small random offsets to the frame indices;\n",
        "                this is useful so we don't always land on even or odd frames\n",
        "            seed: random seed for jittering; if you set this to a fixed value,\n",
        "                you probably want to set it only on the first video \n",
        "    \"\"\"\n",
        "    assert num_frames > 0\n",
        "\n",
        "    capture = cv2.VideoCapture(path)\n",
        "    frame_count = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    if frame_count <= 0: return None\n",
        "\n",
        "    frame_idxs = np.linspace(0, frame_count - 1, num_frames, endpoint=True, dtype=np.int)\n",
        "    if jitter > 0:\n",
        "        np.random.seed(seed)\n",
        "        jitter_offsets = np.random.randint(-jitter, jitter, len(frame_idxs))\n",
        "        frame_idxs = np.clip(frame_idxs + jitter_offsets, 0, frame_count - 1)\n",
        "\n",
        "    result = _read_frames_at_indices(path, capture, frame_idxs)\n",
        "    capture.release()\n",
        "    return result\n",
        "\n",
        "def isotropically_resize_image(img, size, resample=cv2.INTER_AREA):\n",
        "    h, w = img.shape[:2]\n",
        "    if w > h:\n",
        "        h = h * size // w\n",
        "        w = size\n",
        "    else:\n",
        "        w = w * size // h\n",
        "        h = size\n",
        "\n",
        "    resized = cv2.resize(img, (w, h), interpolation=resample)\n",
        "    return resized\n",
        "\n",
        "\n",
        "def make_square_image(img):\n",
        "    h, w = img.shape[:2]\n",
        "    size = max(h, w)\n",
        "    t = 0\n",
        "    b = size - h\n",
        "    l = 0\n",
        "    r = size - w\n",
        "    return cv2.copyMakeBorder(img, t, b, l, r, cv2.BORDER_CONSTANT, value=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRqsGhApXsMp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "a7d5a1d8-a4d6-4c47-8144-88446393bb4d"
      },
      "source": [
        "sys.path.insert(1,'/content/drive/My Drive/YoloV2' )\n",
        "import yolov2\n",
        "\n",
        "mobilenetv2 = yolov2.load_mobilenetv2_224_075_detector(\"/content/drive/My Drive/YoloV2/facedetection-mobilenetv2-size224-alpha0.75.h5\")\n",
        "yolo_model = yolov2.FaceDetector(model=mobilenetv2)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "133D8ZN-XwzF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_faces(frames):\n",
        "    faces = []\n",
        "    for face in frames:\n",
        "        yolo_boxes = yolo_model.detect(face, 0.7)\n",
        "        yb = yolov2.get_boxes_points(yolo_boxes, face.shape)\n",
        "        \n",
        "        for b in yb:\n",
        "            lx, ly, rx, ry = b\n",
        "            # x, y, w, h here\n",
        "            # ax.add_patch(Rectangle((lx,ly),rx - lx,ry - ly,linewidth=2,edgecolor='red',facecolor='none'))\n",
        "            img_crop = face[ly:ry, lx:rx]\n",
        "            resized_face = isotropically_resize_image(img_crop, input_size)\n",
        "            resized_face = make_square_image(resized_face)\n",
        "            faces.append(resized_face)\n",
        "    return faces"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvnwlfHhX-WS",
        "colab_type": "text"
      },
      "source": [
        "# **Data Prep**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qDYWjAvYIoL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "02bfa9367a354cfbb02dc2238faa7dbd",
            "0e92aec9911f41f39798ca5e1f7c6a2d",
            "6afb44d74c09454091f7cafe8da0d51d",
            "46f5dfaa9b714e739126403a1334d6c0",
            "03456b0e1d784db6b8379186713bb664",
            "18846247d24d44b6bf9c43b652d8e14d",
            "80e9ec631ed147a19ec46ca95edefaf6",
            "f88b8bd442d34288a0bcb26d0e36bb34"
          ]
        },
        "outputId": "4931777f-a80c-4796-feec-4ebbb429317a"
      },
      "source": [
        "for path in tqdm(video_dir):\n",
        "    if(os.path.exists(path[0]) == 0):\n",
        "        print(path)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "02bfa9367a354cfbb02dc2238faa7dbd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exbK1uqk-hDy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_orig = []\n",
        "y_orig = []\n",
        "X_test = []\n",
        "Y_test = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrOujJGsYViu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "d8499e353aea4f6db9c6e333a8ad1575",
            "d4315aabec3d4114abfc416bb9d286f9",
            "e6056a8cfd9e41bba66e9987dec1856e",
            "7015728a68ea4816b0fd84e68a1c1cdf",
            "e624d9b0125e4eb68053ca81354c837c",
            "cd22c6c16c1a4190a4bb0c85fe32e0cb",
            "2d70e0c978ca4cc09a1395441518f3f9",
            "071d9d43f9984c2683bc508d74e331da"
          ]
        },
        "outputId": "3c0c92f8-4188-4364-90ef-20a906e84129"
      },
      "source": [
        "for f in tqdm(video_dir):\n",
        "    try:\n",
        "        frames = read_frames(f[0])\n",
        "        faces = get_faces(frames)\n",
        "        x_orig.extend(faces)\n",
        "        y_orig.extend([f[1]] * len(faces))\n",
        "    except Exception as e:\n",
        "        print(\"Error on video %s: %s\" % (f[0], str(e)))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8499e353aea4f6db9c6e333a8ad1575",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Error on video /content/drive/My Drive/Dataset/dfdc_train_part_19/uvpcmbutwe.mp4: \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgziKR5C-_RX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_np = np.array(x_orig, dtype=\"float32\") / 255.0\n",
        "y_np = np.array(y_orig)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_dTtLoW_OvA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "56db8e92-67d1-44a9-ff40-49c48436be30"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "(X_train, X_val, Y_train, Y_val) = train_test_split(x_np, y_np, test_size=0.25, random_state=42)\n",
        "\n",
        "Y_train = to_categorical(Y_train, num_classes=2)\n",
        "Y_val = to_categorical(Y_val, num_classes=2)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fMmR4mA_5Kw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n",
        "\theight_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
        "\thorizontal_flip=True, fill_mode=\"nearest\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzzdlMQlACwx",
        "colab_type": "text"
      },
      "source": [
        "#LeNet Def"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfCbbtkFAFv-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras import backend as K\n",
        "\n",
        "class LeNet:\n",
        "\t@staticmethod\n",
        "\tdef build(width, height, depth, classes):\n",
        "\t\t# initialize the model\n",
        "\t\tmodel = Sequential()\n",
        "\t\tinputShape = (height, width, depth)\n",
        "\t\t# if we are using \"channels first\", update the input shape\n",
        "\t\tif K.image_data_format() == \"channels_first\":\n",
        "\t\t\tinputShape = (depth, height, width)\n",
        "   \n",
        "        # first set of CONV => RELU => POOL layers\n",
        "\t\tmodel.add(Conv2D(256, (5, 5), padding=\"same\", input_shape=inputShape))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "  \n",
        "        # second set of CONV => RELU => POOL layers\n",
        "\t\tmodel.add(Conv2D(256, (5, 5), padding=\"same\"))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "  \n",
        "        # first (and only) set of FC => RELU layers\n",
        "\t\tmodel.add(Flatten())\n",
        "\t\tmodel.add(Dense(512))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\t# softmax classifier\n",
        "\t\tmodel.add(Dense(classes))\n",
        "\t\tmodel.add(Activation(\"softmax\"))\n",
        "\t\t# return the constructed network architecture\n",
        "\t\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-o3nj0zYAgDf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 25\n",
        "INIT_LR = 1e-3\n",
        "BS = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfF7WSAtA0d_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "\n",
        "model = LeNet.build(width=224, height=224, depth=3, classes=2)\n",
        "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "model.compile(loss=\"binary_crossentropy\", \n",
        "              optimizer=opt,\n",
        "\t          metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sghQGo1vBG2n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "outputId": "6a844645-b092-4707-ce3c-3cad0ebfc1ea"
      },
      "source": [
        "H = model.fit_generator(aug.flow(X_train, Y_train, batch_size=BS),\n",
        "\tvalidation_data=(X_val, Y_val), steps_per_epoch=len(X_train) // BS,\n",
        "\tepochs=EPOCHS, verbose=1)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-c443837c0014>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m H = model.fit_generator(aug.flow(X_train, Y_train, batch_size=BS),\n\u001b[1;32m      2\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mBS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \tepochs=EPOCHS, verbose=1)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3631\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3632\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3633\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3634\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted: OOM when allocating tensor with shape[32,256,224,224] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node conv2d_3/convolution}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[metrics_1/accuracy/Identity/_1827]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted: OOM when allocating tensor with shape[32,256,224,224] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node conv2d_3/convolution}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAXW-2HPf_M-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3b2ec6b-d31d-46a9-d4ce-94346e83d30a"
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "538"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    }
  ]
}