{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np \n",
    "import cv2\n",
    "import imageio\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from collections import OrderedDict\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using cache found in C:\\Users\\sowme/.cache\\torch\\hub\\pytorch_vision_v0.6.0\n"
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.6.0', 'densenet161', pretrained=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'in_features'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-540c55b21d41>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mn_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m classifier = nn.Sequential(\n\u001b[0;32m      4\u001b[0m             \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m512\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dfdcpy37-env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    574\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[1;32m--> 576\u001b[1;33m             type(self).__name__, name))\n\u001b[0m\u001b[0;32m    577\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'in_features'"
     ]
    }
   ],
   "source": [
    "n_inputs = model.classifier.in_features\n",
    "\n",
    "classifier = nn.Sequential(\n",
    "            nn.Linear(n_inputs, 512),  \n",
    "            nn.ReLU(), \n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128,1)         \n",
    ")\n",
    "\n",
    "model.classifier = classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "DenseNet(\n  (features): Sequential(\n    (conv0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (norm0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu0): ReLU(inplace=True)\n    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (denseblock1): _DenseBlock(\n      (denselayer1): _DenseLayer(\n        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer2): _DenseLayer(\n        (norm1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(144, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer3): _DenseLayer(\n        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer4): _DenseLayer(\n        (norm1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(240, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer5): _DenseLayer(\n        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer6): _DenseLayer(\n        (norm1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(336, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n    )\n    (transition1): _Transition(\n      (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n    )\n    (denseblock2): _DenseBlock(\n      (denselayer1): _DenseLayer(\n        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer2): _DenseLayer(\n        (norm1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(240, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer3): _DenseLayer(\n        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer4): _DenseLayer(\n        (norm1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(336, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer5): _DenseLayer(\n        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer6): _DenseLayer(\n        (norm1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(432, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer7): _DenseLayer(\n        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer8): _DenseLayer(\n        (norm1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(528, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer9): _DenseLayer(\n        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer10): _DenseLayer(\n        (norm1): BatchNorm2d(624, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(624, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer11): _DenseLayer(\n        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer12): _DenseLayer(\n        (norm1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(720, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n    )\n    (transition2): _Transition(\n      (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n    )\n    (denseblock3): _DenseBlock(\n      (denselayer1): _DenseLayer(\n        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer2): _DenseLayer(\n        (norm1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(432, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer3): _DenseLayer(\n        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer4): _DenseLayer(\n        (norm1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(528, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer5): _DenseLayer(\n        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer6): _DenseLayer(\n        (norm1): BatchNorm2d(624, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(624, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer7): _DenseLayer(\n        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer8): _DenseLayer(\n        (norm1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(720, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer9): _DenseLayer(\n        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer10): _DenseLayer(\n        (norm1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(816, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer11): _DenseLayer(\n        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(864, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer12): _DenseLayer(\n        (norm1): BatchNorm2d(912, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(912, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer13): _DenseLayer(\n        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(960, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer14): _DenseLayer(\n        (norm1): BatchNorm2d(1008, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1008, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer15): _DenseLayer(\n        (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer16): _DenseLayer(\n        (norm1): BatchNorm2d(1104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1104, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer17): _DenseLayer(\n        (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer18): _DenseLayer(\n        (norm1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1200, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer19): _DenseLayer(\n        (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1248, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer20): _DenseLayer(\n        (norm1): BatchNorm2d(1296, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1296, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer21): _DenseLayer(\n        (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1344, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer22): _DenseLayer(\n        (norm1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1392, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer23): _DenseLayer(\n        (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1440, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer24): _DenseLayer(\n        (norm1): BatchNorm2d(1488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1488, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer25): _DenseLayer(\n        (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1536, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer26): _DenseLayer(\n        (norm1): BatchNorm2d(1584, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1584, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer27): _DenseLayer(\n        (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1632, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer28): _DenseLayer(\n        (norm1): BatchNorm2d(1680, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1680, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer29): _DenseLayer(\n        (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1728, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer30): _DenseLayer(\n        (norm1): BatchNorm2d(1776, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1776, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer31): _DenseLayer(\n        (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1824, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer32): _DenseLayer(\n        (norm1): BatchNorm2d(1872, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1872, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer33): _DenseLayer(\n        (norm1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1920, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer34): _DenseLayer(\n        (norm1): BatchNorm2d(1968, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1968, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer35): _DenseLayer(\n        (norm1): BatchNorm2d(2016, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(2016, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer36): _DenseLayer(\n        (norm1): BatchNorm2d(2064, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(2064, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n    )\n    (transition3): _Transition(\n      (norm): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv): Conv2d(2112, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n    )\n    (denseblock4): _DenseBlock(\n      (denselayer1): _DenseLayer(\n        (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer2): _DenseLayer(\n        (norm1): BatchNorm2d(1104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1104, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer3): _DenseLayer(\n        (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer4): _DenseLayer(\n        (norm1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1200, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer5): _DenseLayer(\n        (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1248, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer6): _DenseLayer(\n        (norm1): BatchNorm2d(1296, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1296, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer7): _DenseLayer(\n        (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1344, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer8): _DenseLayer(\n        (norm1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1392, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer9): _DenseLayer(\n        (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1440, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer10): _DenseLayer(\n        (norm1): BatchNorm2d(1488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1488, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer11): _DenseLayer(\n        (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1536, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer12): _DenseLayer(\n        (norm1): BatchNorm2d(1584, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1584, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer13): _DenseLayer(\n        (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1632, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer14): _DenseLayer(\n        (norm1): BatchNorm2d(1680, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1680, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer15): _DenseLayer(\n        (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1728, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer16): _DenseLayer(\n        (norm1): BatchNorm2d(1776, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1776, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer17): _DenseLayer(\n        (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1824, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer18): _DenseLayer(\n        (norm1): BatchNorm2d(1872, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1872, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer19): _DenseLayer(\n        (norm1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1920, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer20): _DenseLayer(\n        (norm1): BatchNorm2d(1968, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1968, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer21): _DenseLayer(\n        (norm1): BatchNorm2d(2016, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(2016, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer22): _DenseLayer(\n        (norm1): BatchNorm2d(2064, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(2064, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer23): _DenseLayer(\n        (norm1): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(2112, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer24): _DenseLayer(\n        (norm1): BatchNorm2d(2160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(2160, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n    )\n    (norm5): BatchNorm2d(2208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (classifier): Sequential(\n    (0): Linear(in_features=2208, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.4, inplace=False)\n    (3): Linear(in_features=256, out_features=1, bias=True)\n  )\n)"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1         [-1, 96, 112, 112]          14,112\n       BatchNorm2d-2         [-1, 96, 112, 112]             192\n              ReLU-3         [-1, 96, 112, 112]               0\n         MaxPool2d-4           [-1, 96, 56, 56]               0\n       BatchNorm2d-5           [-1, 96, 56, 56]             192\n              ReLU-6           [-1, 96, 56, 56]               0\n            Conv2d-7          [-1, 192, 56, 56]          18,432\n       BatchNorm2d-8          [-1, 192, 56, 56]             384\n              ReLU-9          [-1, 192, 56, 56]               0\n           Conv2d-10           [-1, 48, 56, 56]          82,944\n      BatchNorm2d-11          [-1, 144, 56, 56]             288\n             ReLU-12          [-1, 144, 56, 56]               0\n           Conv2d-13          [-1, 192, 56, 56]          27,648\n      BatchNorm2d-14          [-1, 192, 56, 56]             384\n             ReLU-15          [-1, 192, 56, 56]               0\n           Conv2d-16           [-1, 48, 56, 56]          82,944\n      BatchNorm2d-17          [-1, 192, 56, 56]             384\n             ReLU-18          [-1, 192, 56, 56]               0\n           Conv2d-19          [-1, 192, 56, 56]          36,864\n      BatchNorm2d-20          [-1, 192, 56, 56]             384\n             ReLU-21          [-1, 192, 56, 56]               0\n           Conv2d-22           [-1, 48, 56, 56]          82,944\n      BatchNorm2d-23          [-1, 240, 56, 56]             480\n             ReLU-24          [-1, 240, 56, 56]               0\n           Conv2d-25          [-1, 192, 56, 56]          46,080\n      BatchNorm2d-26          [-1, 192, 56, 56]             384\n             ReLU-27          [-1, 192, 56, 56]               0\n           Conv2d-28           [-1, 48, 56, 56]          82,944\n      BatchNorm2d-29          [-1, 288, 56, 56]             576\n             ReLU-30          [-1, 288, 56, 56]               0\n           Conv2d-31          [-1, 192, 56, 56]          55,296\n      BatchNorm2d-32          [-1, 192, 56, 56]             384\n             ReLU-33          [-1, 192, 56, 56]               0\n           Conv2d-34           [-1, 48, 56, 56]          82,944\n      BatchNorm2d-35          [-1, 336, 56, 56]             672\n             ReLU-36          [-1, 336, 56, 56]               0\n           Conv2d-37          [-1, 192, 56, 56]          64,512\n      BatchNorm2d-38          [-1, 192, 56, 56]             384\n             ReLU-39          [-1, 192, 56, 56]               0\n           Conv2d-40           [-1, 48, 56, 56]          82,944\n      BatchNorm2d-41          [-1, 384, 56, 56]             768\n             ReLU-42          [-1, 384, 56, 56]               0\n           Conv2d-43          [-1, 192, 56, 56]          73,728\n        AvgPool2d-44          [-1, 192, 28, 28]               0\n      BatchNorm2d-45          [-1, 192, 28, 28]             384\n             ReLU-46          [-1, 192, 28, 28]               0\n           Conv2d-47          [-1, 192, 28, 28]          36,864\n      BatchNorm2d-48          [-1, 192, 28, 28]             384\n             ReLU-49          [-1, 192, 28, 28]               0\n           Conv2d-50           [-1, 48, 28, 28]          82,944\n      BatchNorm2d-51          [-1, 240, 28, 28]             480\n             ReLU-52          [-1, 240, 28, 28]               0\n           Conv2d-53          [-1, 192, 28, 28]          46,080\n      BatchNorm2d-54          [-1, 192, 28, 28]             384\n             ReLU-55          [-1, 192, 28, 28]               0\n           Conv2d-56           [-1, 48, 28, 28]          82,944\n      BatchNorm2d-57          [-1, 288, 28, 28]             576\n             ReLU-58          [-1, 288, 28, 28]               0\n           Conv2d-59          [-1, 192, 28, 28]          55,296\n      BatchNorm2d-60          [-1, 192, 28, 28]             384\n             ReLU-61          [-1, 192, 28, 28]               0\n           Conv2d-62           [-1, 48, 28, 28]          82,944\n      BatchNorm2d-63          [-1, 336, 28, 28]             672\n             ReLU-64          [-1, 336, 28, 28]               0\n           Conv2d-65          [-1, 192, 28, 28]          64,512\n      BatchNorm2d-66          [-1, 192, 28, 28]             384\n             ReLU-67          [-1, 192, 28, 28]               0\n           Conv2d-68           [-1, 48, 28, 28]          82,944\n      BatchNorm2d-69          [-1, 384, 28, 28]             768\n             ReLU-70          [-1, 384, 28, 28]               0\n           Conv2d-71          [-1, 192, 28, 28]          73,728\n      BatchNorm2d-72          [-1, 192, 28, 28]             384\n             ReLU-73          [-1, 192, 28, 28]               0\n           Conv2d-74           [-1, 48, 28, 28]          82,944\n      BatchNorm2d-75          [-1, 432, 28, 28]             864\n             ReLU-76          [-1, 432, 28, 28]               0\n           Conv2d-77          [-1, 192, 28, 28]          82,944\n      BatchNorm2d-78          [-1, 192, 28, 28]             384\n             ReLU-79          [-1, 192, 28, 28]               0\n           Conv2d-80           [-1, 48, 28, 28]          82,944\n      BatchNorm2d-81          [-1, 480, 28, 28]             960\n             ReLU-82          [-1, 480, 28, 28]               0\n           Conv2d-83          [-1, 192, 28, 28]          92,160\n      BatchNorm2d-84          [-1, 192, 28, 28]             384\n             ReLU-85          [-1, 192, 28, 28]               0\n           Conv2d-86           [-1, 48, 28, 28]          82,944\n      BatchNorm2d-87          [-1, 528, 28, 28]           1,056\n             ReLU-88          [-1, 528, 28, 28]               0\n           Conv2d-89          [-1, 192, 28, 28]         101,376\n      BatchNorm2d-90          [-1, 192, 28, 28]             384\n             ReLU-91          [-1, 192, 28, 28]               0\n           Conv2d-92           [-1, 48, 28, 28]          82,944\n      BatchNorm2d-93          [-1, 576, 28, 28]           1,152\n             ReLU-94          [-1, 576, 28, 28]               0\n           Conv2d-95          [-1, 192, 28, 28]         110,592\n      BatchNorm2d-96          [-1, 192, 28, 28]             384\n             ReLU-97          [-1, 192, 28, 28]               0\n           Conv2d-98           [-1, 48, 28, 28]          82,944\n      BatchNorm2d-99          [-1, 624, 28, 28]           1,248\n            ReLU-100          [-1, 624, 28, 28]               0\n          Conv2d-101          [-1, 192, 28, 28]         119,808\n     BatchNorm2d-102          [-1, 192, 28, 28]             384\n            ReLU-103          [-1, 192, 28, 28]               0\n          Conv2d-104           [-1, 48, 28, 28]          82,944\n     BatchNorm2d-105          [-1, 672, 28, 28]           1,344\n            ReLU-106          [-1, 672, 28, 28]               0\n          Conv2d-107          [-1, 192, 28, 28]         129,024\n     BatchNorm2d-108          [-1, 192, 28, 28]             384\n            ReLU-109          [-1, 192, 28, 28]               0\n          Conv2d-110           [-1, 48, 28, 28]          82,944\n     BatchNorm2d-111          [-1, 720, 28, 28]           1,440\n            ReLU-112          [-1, 720, 28, 28]               0\n          Conv2d-113          [-1, 192, 28, 28]         138,240\n     BatchNorm2d-114          [-1, 192, 28, 28]             384\n            ReLU-115          [-1, 192, 28, 28]               0\n          Conv2d-116           [-1, 48, 28, 28]          82,944\n     BatchNorm2d-117          [-1, 768, 28, 28]           1,536\n            ReLU-118          [-1, 768, 28, 28]               0\n          Conv2d-119          [-1, 384, 28, 28]         294,912\n       AvgPool2d-120          [-1, 384, 14, 14]               0\n     BatchNorm2d-121          [-1, 384, 14, 14]             768\n            ReLU-122          [-1, 384, 14, 14]               0\n          Conv2d-123          [-1, 192, 14, 14]          73,728\n     BatchNorm2d-124          [-1, 192, 14, 14]             384\n            ReLU-125          [-1, 192, 14, 14]               0\n          Conv2d-126           [-1, 48, 14, 14]          82,944\n     BatchNorm2d-127          [-1, 432, 14, 14]             864\n            ReLU-128          [-1, 432, 14, 14]               0\n          Conv2d-129          [-1, 192, 14, 14]          82,944\n     BatchNorm2d-130          [-1, 192, 14, 14]             384\n            ReLU-131          [-1, 192, 14, 14]               0\n          Conv2d-132           [-1, 48, 14, 14]          82,944\n     BatchNorm2d-133          [-1, 480, 14, 14]             960\n            ReLU-134          [-1, 480, 14, 14]               0\n          Conv2d-135          [-1, 192, 14, 14]          92,160\n     BatchNorm2d-136          [-1, 192, 14, 14]             384\n            ReLU-137          [-1, 192, 14, 14]               0\n          Conv2d-138           [-1, 48, 14, 14]          82,944\n     BatchNorm2d-139          [-1, 528, 14, 14]           1,056\n            ReLU-140          [-1, 528, 14, 14]               0\n          Conv2d-141          [-1, 192, 14, 14]         101,376\n     BatchNorm2d-142          [-1, 192, 14, 14]             384\n            ReLU-143          [-1, 192, 14, 14]               0\n          Conv2d-144           [-1, 48, 14, 14]          82,944\n     BatchNorm2d-145          [-1, 576, 14, 14]           1,152\n            ReLU-146          [-1, 576, 14, 14]               0\n          Conv2d-147          [-1, 192, 14, 14]         110,592\n     BatchNorm2d-148          [-1, 192, 14, 14]             384\n            ReLU-149          [-1, 192, 14, 14]               0\n          Conv2d-150           [-1, 48, 14, 14]          82,944\n     BatchNorm2d-151          [-1, 624, 14, 14]           1,248\n            ReLU-152          [-1, 624, 14, 14]               0\n          Conv2d-153          [-1, 192, 14, 14]         119,808\n     BatchNorm2d-154          [-1, 192, 14, 14]             384\n            ReLU-155          [-1, 192, 14, 14]               0\n          Conv2d-156           [-1, 48, 14, 14]          82,944\n     BatchNorm2d-157          [-1, 672, 14, 14]           1,344\n            ReLU-158          [-1, 672, 14, 14]               0\n          Conv2d-159          [-1, 192, 14, 14]         129,024\n     BatchNorm2d-160          [-1, 192, 14, 14]             384\n            ReLU-161          [-1, 192, 14, 14]               0\n          Conv2d-162           [-1, 48, 14, 14]          82,944\n     BatchNorm2d-163          [-1, 720, 14, 14]           1,440\n            ReLU-164          [-1, 720, 14, 14]               0\n          Conv2d-165          [-1, 192, 14, 14]         138,240\n     BatchNorm2d-166          [-1, 192, 14, 14]             384\n            ReLU-167          [-1, 192, 14, 14]               0\n          Conv2d-168           [-1, 48, 14, 14]          82,944\n     BatchNorm2d-169          [-1, 768, 14, 14]           1,536\n            ReLU-170          [-1, 768, 14, 14]               0\n          Conv2d-171          [-1, 192, 14, 14]         147,456\n     BatchNorm2d-172          [-1, 192, 14, 14]             384\n            ReLU-173          [-1, 192, 14, 14]               0\n          Conv2d-174           [-1, 48, 14, 14]          82,944\n     BatchNorm2d-175          [-1, 816, 14, 14]           1,632\n            ReLU-176          [-1, 816, 14, 14]               0\n          Conv2d-177          [-1, 192, 14, 14]         156,672\n     BatchNorm2d-178          [-1, 192, 14, 14]             384\n            ReLU-179          [-1, 192, 14, 14]               0\n          Conv2d-180           [-1, 48, 14, 14]          82,944\n     BatchNorm2d-181          [-1, 864, 14, 14]           1,728\n            ReLU-182          [-1, 864, 14, 14]               0\n          Conv2d-183          [-1, 192, 14, 14]         165,888\n     BatchNorm2d-184          [-1, 192, 14, 14]             384\n            ReLU-185          [-1, 192, 14, 14]               0\n          Conv2d-186           [-1, 48, 14, 14]          82,944\n     BatchNorm2d-187          [-1, 912, 14, 14]           1,824\n            ReLU-188          [-1, 912, 14, 14]               0\n          Conv2d-189          [-1, 192, 14, 14]         175,104\n     BatchNorm2d-190          [-1, 192, 14, 14]             384\n            ReLU-191          [-1, 192, 14, 14]               0\n          Conv2d-192           [-1, 48, 14, 14]          82,944\n     BatchNorm2d-193          [-1, 960, 14, 14]           1,920\n            ReLU-194          [-1, 960, 14, 14]               0\n          Conv2d-195          [-1, 192, 14, 14]         184,320\n     BatchNorm2d-196          [-1, 192, 14, 14]             384\n            ReLU-197          [-1, 192, 14, 14]               0\n          Conv2d-198           [-1, 48, 14, 14]          82,944\n     BatchNorm2d-199         [-1, 1008, 14, 14]           2,016\n            ReLU-200         [-1, 1008, 14, 14]               0\n          Conv2d-201          [-1, 192, 14, 14]         193,536\n     BatchNorm2d-202          [-1, 192, 14, 14]             384\n            ReLU-203          [-1, 192, 14, 14]               0\n          Conv2d-204           [-1, 48, 14, 14]          82,944\n     BatchNorm2d-205         [-1, 1056, 14, 14]           2,112\n            ReLU-206         [-1, 1056, 14, 14]               0\n          Conv2d-207          [-1, 192, 14, 14]         202,752\n     BatchNorm2d-208          [-1, 192, 14, 14]             384\n            ReLU-209          [-1, 192, 14, 14]               0\n          Conv2d-210           [-1, 48, 14, 14]          82,944\n     BatchNorm2d-211         [-1, 1104, 14, 14]           2,208\n            ReLU-212         [-1, 1104, 14, 14]               0\n          Conv2d-213          [-1, 192, 14, 14]         211,968\n     BatchNorm2d-214          [-1, 192, 14, 14]             384\n            ReLU-215          [-1, 192, 14, 14]               0\n          Conv2d-216           [-1, 48, 14, 14]          82,944\n     BatchNorm2d-217         [-1, 1152, 14, 14]           2,304\n            ReLU-218         [-1, 1152, 14, 14]               0\n          Conv2d-219          [-1, 192, 14, 14]         221,184\n     BatchNorm2d-220          [-1, 192, 14, 14]             384\n            ReLU-221          [-1, 192, 14, 14]               0\n          Conv2d-222           [-1, 48, 14, 14]          82,944\n     BatchNorm2d-223         [-1, 1200, 14, 14]           2,400\n            ReLU-224         [-1, 1200, 14, 14]               0\n          Conv2d-225          [-1, 192, 14, 14]         230,400\n     BatchNorm2d-226          [-1, 192, 14, 14]             384\n            ReLU-227          [-1, 192, 14, 14]               0\n          Conv2d-228           [-1, 48, 14, 14]          82,944\n     BatchNorm2d-229         [-1, 1248, 14, 14]           2,496\n            ReLU-230         [-1, 1248, 14, 14]               0\n          Conv2d-231          [-1, 192, 14, 14]         239,616\n     BatchNorm2d-232          [-1, 192, 14, 14]             384\n            ReLU-233          [-1, 192, 14, 14]               0\n          Conv2d-234           [-1, 48, 14, 14]          82,944\n     BatchNorm2d-235         [-1, 1296, 14, 14]           2,592\n            ReLU-236         [-1, 1296, 14, 14]               0\n          Conv2d-237          [-1, 192, 14, 14]         248,832\n     BatchNorm2d-238          [-1, 192, 14, 14]             384\n            ReLU-239          [-1, 192, 14, 14]               0\n          Conv2d-240           [-1, 48, 14, 14]          82,944\n     BatchNorm2d-241         [-1, 1344, 14, 14]           2,688\n            ReLU-242         [-1, 1344, 14, 14]               0\n          Conv2d-243          [-1, 192, 14, 14]         258,048\n     BatchNorm2d-244          [-1, 192, 14, 14]             384\n            ReLU-245          [-1, 192, 14, 14]               0\n          Conv2d-246           [-1, 48, 14, 14]          82,944\n     BatchNorm2d-247         [-1, 1392, 14, 14]           2,784\n            ReLU-248         [-1, 1392, 14, 14]               0\n          Conv2d-249          [-1, 192, 14, 14]         267,264\n     BatchNorm2d-250          [-1, 192, 14, 14]             384\n            ReLU-251          [-1, 192, 14, 14]               0\n          Conv2d-252           [-1, 48, 14, 14]          82,944\n     BatchNorm2d-253         [-1, 1440, 14, 14]           2,880\n            ReLU-254         [-1, 1440, 14, 14]               0\n          Conv2d-255          [-1, 192, 14, 14]         276,480\n     BatchNorm2d-256          [-1, 192, 14, 14]             384\n            ReLU-257          [-1, 192, 14, 14]               0\n          Conv2d-258           [-1, 48, 14, 14]          82,944\n     BatchNorm2d-259         [-1, 1488, 14, 14]           2,976\n            ReLU-260         [-1, 1488, 14, 14]               0\n          Conv2d-261          [-1, 192, 14, 14]         285,696\n     BatchNorm2d-262          [-1, 192, 14, 14]             384\n            ReLU-263          [-1, 192, 14, 14]               0\n          Conv2d-264           [-1, 48, 14, 14]          82,944\n     BatchNorm2d-265         [-1, 1536, 14, 14]           3,072\n            ReLU-266         [-1, 1536, 14, 14]               0\n          Conv2d-267          [-1, 192, 14, 14]         294,912\n     BatchNorm2d-268          [-1, 192, 14, 14]             384\n            ReLU-269          [-1, 192, 14, 14]               0\n          Conv2d-270           [-1, 48, 14, 14]          82,944\n     BatchNorm2d-271         [-1, 1584, 14, 14]           3,168\n            ReLU-272         [-1, 1584, 14, 14]               0\n          Conv2d-273          [-1, 192, 14, 14]         304,128\n     BatchNorm2d-274          [-1, 192, 14, 14]             384\n            ReLU-275          [-1, 192, 14, 14]               0\n          Conv2d-276           [-1, 48, 14, 14]          82,944\n     BatchNorm2d-277         [-1, 1632, 14, 14]           3,264\n            ReLU-278         [-1, 1632, 14, 14]               0\n          Conv2d-279          [-1, 192, 14, 14]         313,344\n     BatchNorm2d-280          [-1, 192, 14, 14]             384\n            ReLU-281          [-1, 192, 14, 14]               0\n          Conv2d-282           [-1, 48, 14, 14]          82,944\n     BatchNorm2d-283         [-1, 1680, 14, 14]           3,360\n            ReLU-284         [-1, 1680, 14, 14]               0\n          Conv2d-285          [-1, 192, 14, 14]         322,560\n     BatchNorm2d-286          [-1, 192, 14, 14]             384\n            ReLU-287          [-1, 192, 14, 14]               0\n          Conv2d-288           [-1, 48, 14, 14]          82,944\n     BatchNorm2d-289         [-1, 1728, 14, 14]           3,456\n            ReLU-290         [-1, 1728, 14, 14]               0\n          Conv2d-291          [-1, 192, 14, 14]         331,776\n     BatchNorm2d-292          [-1, 192, 14, 14]             384\n            ReLU-293          [-1, 192, 14, 14]               0\n          Conv2d-294           [-1, 48, 14, 14]          82,944\n     BatchNorm2d-295         [-1, 1776, 14, 14]           3,552\n            ReLU-296         [-1, 1776, 14, 14]               0\n          Conv2d-297          [-1, 192, 14, 14]         340,992\n     BatchNorm2d-298          [-1, 192, 14, 14]             384\n            ReLU-299          [-1, 192, 14, 14]               0\n          Conv2d-300           [-1, 48, 14, 14]          82,944\n     BatchNorm2d-301         [-1, 1824, 14, 14]           3,648\n            ReLU-302         [-1, 1824, 14, 14]               0\n          Conv2d-303          [-1, 192, 14, 14]         350,208\n     BatchNorm2d-304          [-1, 192, 14, 14]             384\n            ReLU-305          [-1, 192, 14, 14]               0\n          Conv2d-306           [-1, 48, 14, 14]          82,944\n     BatchNorm2d-307         [-1, 1872, 14, 14]           3,744\n            ReLU-308         [-1, 1872, 14, 14]               0\n          Conv2d-309          [-1, 192, 14, 14]         359,424\n     BatchNorm2d-310          [-1, 192, 14, 14]             384\n            ReLU-311          [-1, 192, 14, 14]               0\n          Conv2d-312           [-1, 48, 14, 14]          82,944\n     BatchNorm2d-313         [-1, 1920, 14, 14]           3,840\n            ReLU-314         [-1, 1920, 14, 14]               0\n          Conv2d-315          [-1, 192, 14, 14]         368,640\n     BatchNorm2d-316          [-1, 192, 14, 14]             384\n            ReLU-317          [-1, 192, 14, 14]               0\n          Conv2d-318           [-1, 48, 14, 14]          82,944\n     BatchNorm2d-319         [-1, 1968, 14, 14]           3,936\n            ReLU-320         [-1, 1968, 14, 14]               0\n          Conv2d-321          [-1, 192, 14, 14]         377,856\n     BatchNorm2d-322          [-1, 192, 14, 14]             384\n            ReLU-323          [-1, 192, 14, 14]               0\n          Conv2d-324           [-1, 48, 14, 14]          82,944\n     BatchNorm2d-325         [-1, 2016, 14, 14]           4,032\n            ReLU-326         [-1, 2016, 14, 14]               0\n          Conv2d-327          [-1, 192, 14, 14]         387,072\n     BatchNorm2d-328          [-1, 192, 14, 14]             384\n            ReLU-329          [-1, 192, 14, 14]               0\n          Conv2d-330           [-1, 48, 14, 14]          82,944\n     BatchNorm2d-331         [-1, 2064, 14, 14]           4,128\n            ReLU-332         [-1, 2064, 14, 14]               0\n          Conv2d-333          [-1, 192, 14, 14]         396,288\n     BatchNorm2d-334          [-1, 192, 14, 14]             384\n            ReLU-335          [-1, 192, 14, 14]               0\n          Conv2d-336           [-1, 48, 14, 14]          82,944\n     BatchNorm2d-337         [-1, 2112, 14, 14]           4,224\n            ReLU-338         [-1, 2112, 14, 14]               0\n          Conv2d-339         [-1, 1056, 14, 14]       2,230,272\n       AvgPool2d-340           [-1, 1056, 7, 7]               0\n     BatchNorm2d-341           [-1, 1056, 7, 7]           2,112\n            ReLU-342           [-1, 1056, 7, 7]               0\n          Conv2d-343            [-1, 192, 7, 7]         202,752\n     BatchNorm2d-344            [-1, 192, 7, 7]             384\n            ReLU-345            [-1, 192, 7, 7]               0\n          Conv2d-346             [-1, 48, 7, 7]          82,944\n     BatchNorm2d-347           [-1, 1104, 7, 7]           2,208\n            ReLU-348           [-1, 1104, 7, 7]               0\n          Conv2d-349            [-1, 192, 7, 7]         211,968\n     BatchNorm2d-350            [-1, 192, 7, 7]             384\n            ReLU-351            [-1, 192, 7, 7]               0\n          Conv2d-352             [-1, 48, 7, 7]          82,944\n     BatchNorm2d-353           [-1, 1152, 7, 7]           2,304\n            ReLU-354           [-1, 1152, 7, 7]               0\n          Conv2d-355            [-1, 192, 7, 7]         221,184\n     BatchNorm2d-356            [-1, 192, 7, 7]             384\n            ReLU-357            [-1, 192, 7, 7]               0\n          Conv2d-358             [-1, 48, 7, 7]          82,944\n     BatchNorm2d-359           [-1, 1200, 7, 7]           2,400\n            ReLU-360           [-1, 1200, 7, 7]               0\n          Conv2d-361            [-1, 192, 7, 7]         230,400\n     BatchNorm2d-362            [-1, 192, 7, 7]             384\n            ReLU-363            [-1, 192, 7, 7]               0\n          Conv2d-364             [-1, 48, 7, 7]          82,944\n     BatchNorm2d-365           [-1, 1248, 7, 7]           2,496\n            ReLU-366           [-1, 1248, 7, 7]               0\n          Conv2d-367            [-1, 192, 7, 7]         239,616\n     BatchNorm2d-368            [-1, 192, 7, 7]             384\n            ReLU-369            [-1, 192, 7, 7]               0\n          Conv2d-370             [-1, 48, 7, 7]          82,944\n     BatchNorm2d-371           [-1, 1296, 7, 7]           2,592\n            ReLU-372           [-1, 1296, 7, 7]               0\n          Conv2d-373            [-1, 192, 7, 7]         248,832\n     BatchNorm2d-374            [-1, 192, 7, 7]             384\n            ReLU-375            [-1, 192, 7, 7]               0\n          Conv2d-376             [-1, 48, 7, 7]          82,944\n     BatchNorm2d-377           [-1, 1344, 7, 7]           2,688\n            ReLU-378           [-1, 1344, 7, 7]               0\n          Conv2d-379            [-1, 192, 7, 7]         258,048\n     BatchNorm2d-380            [-1, 192, 7, 7]             384\n            ReLU-381            [-1, 192, 7, 7]               0\n          Conv2d-382             [-1, 48, 7, 7]          82,944\n     BatchNorm2d-383           [-1, 1392, 7, 7]           2,784\n            ReLU-384           [-1, 1392, 7, 7]               0\n          Conv2d-385            [-1, 192, 7, 7]         267,264\n     BatchNorm2d-386            [-1, 192, 7, 7]             384\n            ReLU-387            [-1, 192, 7, 7]               0\n          Conv2d-388             [-1, 48, 7, 7]          82,944\n     BatchNorm2d-389           [-1, 1440, 7, 7]           2,880\n            ReLU-390           [-1, 1440, 7, 7]               0\n          Conv2d-391            [-1, 192, 7, 7]         276,480\n     BatchNorm2d-392            [-1, 192, 7, 7]             384\n            ReLU-393            [-1, 192, 7, 7]               0\n          Conv2d-394             [-1, 48, 7, 7]          82,944\n     BatchNorm2d-395           [-1, 1488, 7, 7]           2,976\n            ReLU-396           [-1, 1488, 7, 7]               0\n          Conv2d-397            [-1, 192, 7, 7]         285,696\n     BatchNorm2d-398            [-1, 192, 7, 7]             384\n            ReLU-399            [-1, 192, 7, 7]               0\n          Conv2d-400             [-1, 48, 7, 7]          82,944\n     BatchNorm2d-401           [-1, 1536, 7, 7]           3,072\n            ReLU-402           [-1, 1536, 7, 7]               0\n          Conv2d-403            [-1, 192, 7, 7]         294,912\n     BatchNorm2d-404            [-1, 192, 7, 7]             384\n            ReLU-405            [-1, 192, 7, 7]               0\n          Conv2d-406             [-1, 48, 7, 7]          82,944\n     BatchNorm2d-407           [-1, 1584, 7, 7]           3,168\n            ReLU-408           [-1, 1584, 7, 7]               0\n          Conv2d-409            [-1, 192, 7, 7]         304,128\n     BatchNorm2d-410            [-1, 192, 7, 7]             384\n            ReLU-411            [-1, 192, 7, 7]               0\n          Conv2d-412             [-1, 48, 7, 7]          82,944\n     BatchNorm2d-413           [-1, 1632, 7, 7]           3,264\n            ReLU-414           [-1, 1632, 7, 7]               0\n          Conv2d-415            [-1, 192, 7, 7]         313,344\n     BatchNorm2d-416            [-1, 192, 7, 7]             384\n            ReLU-417            [-1, 192, 7, 7]               0\n          Conv2d-418             [-1, 48, 7, 7]          82,944\n     BatchNorm2d-419           [-1, 1680, 7, 7]           3,360\n            ReLU-420           [-1, 1680, 7, 7]               0\n          Conv2d-421            [-1, 192, 7, 7]         322,560\n     BatchNorm2d-422            [-1, 192, 7, 7]             384\n            ReLU-423            [-1, 192, 7, 7]               0\n          Conv2d-424             [-1, 48, 7, 7]          82,944\n     BatchNorm2d-425           [-1, 1728, 7, 7]           3,456\n            ReLU-426           [-1, 1728, 7, 7]               0\n          Conv2d-427            [-1, 192, 7, 7]         331,776\n     BatchNorm2d-428            [-1, 192, 7, 7]             384\n            ReLU-429            [-1, 192, 7, 7]               0\n          Conv2d-430             [-1, 48, 7, 7]          82,944\n     BatchNorm2d-431           [-1, 1776, 7, 7]           3,552\n            ReLU-432           [-1, 1776, 7, 7]               0\n          Conv2d-433            [-1, 192, 7, 7]         340,992\n     BatchNorm2d-434            [-1, 192, 7, 7]             384\n            ReLU-435            [-1, 192, 7, 7]               0\n          Conv2d-436             [-1, 48, 7, 7]          82,944\n     BatchNorm2d-437           [-1, 1824, 7, 7]           3,648\n            ReLU-438           [-1, 1824, 7, 7]               0\n          Conv2d-439            [-1, 192, 7, 7]         350,208\n     BatchNorm2d-440            [-1, 192, 7, 7]             384\n            ReLU-441            [-1, 192, 7, 7]               0\n          Conv2d-442             [-1, 48, 7, 7]          82,944\n     BatchNorm2d-443           [-1, 1872, 7, 7]           3,744\n            ReLU-444           [-1, 1872, 7, 7]               0\n          Conv2d-445            [-1, 192, 7, 7]         359,424\n     BatchNorm2d-446            [-1, 192, 7, 7]             384\n            ReLU-447            [-1, 192, 7, 7]               0\n          Conv2d-448             [-1, 48, 7, 7]          82,944\n     BatchNorm2d-449           [-1, 1920, 7, 7]           3,840\n            ReLU-450           [-1, 1920, 7, 7]               0\n          Conv2d-451            [-1, 192, 7, 7]         368,640\n     BatchNorm2d-452            [-1, 192, 7, 7]             384\n            ReLU-453            [-1, 192, 7, 7]               0\n          Conv2d-454             [-1, 48, 7, 7]          82,944\n     BatchNorm2d-455           [-1, 1968, 7, 7]           3,936\n            ReLU-456           [-1, 1968, 7, 7]               0\n          Conv2d-457            [-1, 192, 7, 7]         377,856\n     BatchNorm2d-458            [-1, 192, 7, 7]             384\n            ReLU-459            [-1, 192, 7, 7]               0\n          Conv2d-460             [-1, 48, 7, 7]          82,944\n     BatchNorm2d-461           [-1, 2016, 7, 7]           4,032\n            ReLU-462           [-1, 2016, 7, 7]               0\n          Conv2d-463            [-1, 192, 7, 7]         387,072\n     BatchNorm2d-464            [-1, 192, 7, 7]             384\n            ReLU-465            [-1, 192, 7, 7]               0\n          Conv2d-466             [-1, 48, 7, 7]          82,944\n     BatchNorm2d-467           [-1, 2064, 7, 7]           4,128\n            ReLU-468           [-1, 2064, 7, 7]               0\n          Conv2d-469            [-1, 192, 7, 7]         396,288\n     BatchNorm2d-470            [-1, 192, 7, 7]             384\n            ReLU-471            [-1, 192, 7, 7]               0\n          Conv2d-472             [-1, 48, 7, 7]          82,944\n     BatchNorm2d-473           [-1, 2112, 7, 7]           4,224\n            ReLU-474           [-1, 2112, 7, 7]               0\n          Conv2d-475            [-1, 192, 7, 7]         405,504\n     BatchNorm2d-476            [-1, 192, 7, 7]             384\n            ReLU-477            [-1, 192, 7, 7]               0\n          Conv2d-478             [-1, 48, 7, 7]          82,944\n     BatchNorm2d-479           [-1, 2160, 7, 7]           4,320\n            ReLU-480           [-1, 2160, 7, 7]               0\n          Conv2d-481            [-1, 192, 7, 7]         414,720\n     BatchNorm2d-482            [-1, 192, 7, 7]             384\n            ReLU-483            [-1, 192, 7, 7]               0\n          Conv2d-484             [-1, 48, 7, 7]          82,944\n     BatchNorm2d-485           [-1, 2208, 7, 7]           4,416\n          Linear-486                  [-1, 256]         565,504\n            ReLU-487                  [-1, 256]               0\n         Dropout-488                  [-1, 256]               0\n          Linear-489                    [-1, 1]             257\n================================================================\nTotal params: 27,037,761\nTrainable params: 27,037,761\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.57\nForward/backward pass size (MB): 536.83\nParams size (MB): 103.14\nEstimated Total Size (MB): 640.54\n----------------------------------------------------------------\n\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(tensor(27037761), tensor(27037761))"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "summary(model, (3,224,224), device='cuda')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37364bitdfdcpy37envconda69be420fbf944be7a8f2b2400cd01596",
   "display_name": "Python 3.7.3 64-bit ('dfdcpy37-env': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}